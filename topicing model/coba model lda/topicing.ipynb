{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>comments</th>\n",
       "      <th>bank</th>\n",
       "      <th>date</th>\n",
       "      <th>platform</th>\n",
       "      <th>label</th>\n",
       "      <th>topik</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>keren sekali transmart bintang melanda bintang...</td>\n",
       "      <td>Bank Mega</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>tidak pernah kabari menerapkan</td>\n",
       "      <td>Bank Mega</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>2</td>\n",
       "      <td>cc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>keren bht</td>\n",
       "      <td>Bank Mega</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>transmart makssar masih kurang lengkap barangnya</td>\n",
       "      <td>Bank Mega</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>2</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>dan transmart keren oke wajah tersenyum dengan...</td>\n",
       "      <td>Bank Mega</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>service</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                           comments       bank  \\\n",
       "0   1  keren sekali transmart bintang melanda bintang...  Bank Mega   \n",
       "1   2                     tidak pernah kabari menerapkan  Bank Mega   \n",
       "2   3                                          keren bht  Bank Mega   \n",
       "3   4   transmart makssar masih kurang lengkap barangnya  Bank Mega   \n",
       "4   5  dan transmart keren oke wajah tersenyum dengan...  Bank Mega   \n",
       "\n",
       "        date   platform  label    topik  Unnamed: 7  \n",
       "0 2023-05-07  Instagram      0  service         NaN  \n",
       "1 2023-05-07  Instagram      2       cc         NaN  \n",
       "2 2023-05-07  Instagram      0  service         NaN  \n",
       "3 2023-05-07  Instagram      2  service         NaN  \n",
       "4 2023-05-07  Instagram      0  service         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"output_file.xlsx\",sheet_name=\"Sheet1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          no                                           comments       bank  \\\n",
      "0          1                         Keren banget Transmart ðŸ¤©ðŸ¤©ðŸ¤©  Bank Mega   \n",
      "1          2                       gapernah di kabarin apply cc  Bank Mega   \n",
      "2          3                                          Keren bht  Bank Mega   \n",
      "3          4  Transmart di makssar masih kurang lengkap bara...  Bank Mega   \n",
      "4          5                @bankmegaid & Transmart keren Oke ðŸ˜  Bank Mega   \n",
      "...      ...                                                ...        ...   \n",
      "58974  58975             Gimana bisa dapat lg mohon bantuan nya        BRI   \n",
      "58975  58976  Kak untuk kak diary pkh bansos saya mau tnya s...        BRI   \n",
      "58976  58977                                 pkh apa bnt ya bun        BRI   \n",
      "58977  58978                   Mau pinjam tapi ga bisa  cara ny        BRI   \n",
      "58978  58979                   Di coba kakak..offline juga bisa        BRI   \n",
      "\n",
      "            date   platform Label (1,0,-1)  \n",
      "0     2023-05-07  Instagram              1  \n",
      "1     2023-05-07  Instagram             -1  \n",
      "2     2023-05-07  Instagram              1  \n",
      "3     2023-05-07  Instagram             -1  \n",
      "4     2023-05-07  Instagram              1  \n",
      "...          ...        ...            ...  \n",
      "58974 2023-05-23    YouTube            NaN  \n",
      "58975 2023-05-23    YouTube            NaN  \n",
      "58976 2023-05-26    YouTube            NaN  \n",
      "58977 2023-05-27    YouTube            NaN  \n",
      "58978 2023-05-27    YouTube            NaN  \n",
      "\n",
      "[58979 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "excel_file_path = 'curr_train.xlsx'\n",
    "\n",
    "sheets_dict = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "combined_df = pd.concat(sheets_dict.values(), ignore_index=True)\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'id_stopwords.txt'\n",
    "id_stopwords = []\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        id_stopwords.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keren', 'transmart', 'bintang', 'melanda', 'bintang', 'melanda', 'bintang', 'melanda']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jmspa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('indonesian')\n",
    "stop_words.extend(id_stopwords)\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data = df.comments.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (1, 1), (2, 3), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.035*\"seriusbisa\" + 0.032*\"wajah\" + 0.031*\"beli\" + 0.029*\"mega\" + '\n",
      "  '0.027*\"bank\" + 0.023*\"tersenyum\" + 0.019*\"hati\" + 0.015*\"semoga\" + '\n",
      "  '0.013*\"ikutan\" + 0.013*\"mata\"'),\n",
      " (1,\n",
      "  '0.035*\"beli\" + 0.032*\"wajah\" + 0.029*\"seriusbisa\" + 0.021*\"mata\" + '\n",
      "  '0.018*\"mega\" + 0.017*\"tersenyum\" + 0.016*\"bank\" + 0.012*\"hati\" + '\n",
      "  '0.009*\"tangan\" + 0.008*\"air\"'),\n",
      " (2,\n",
      "  '0.067*\"hati\" + 0.038*\"seriusbisa\" + 0.034*\"beli\" + 0.028*\"wajah\" + '\n",
      "  '0.026*\"merah\" + 0.025*\"mata\" + 0.019*\"tersenyum\" + 0.010*\"bank\" + '\n",
      "  '0.010*\"kartu\" + 0.009*\"kredit\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# number of topics\n",
    "num_topics = 3\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/results/ldavis_prepared_3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     11\u001b[0m     LDAvis_prepared \u001b[38;5;241m=\u001b[39m pyLDAvis\u001b[38;5;241m.\u001b[39mgensim\u001b[38;5;241m.\u001b[39mprepare(lda_model, corpus, id2word)\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLDAvis_data_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     13\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(LDAvis_prepared, f)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# load the pre-prepared pyLDAvis data from disk\u001b[39;00m\n",
      "File \u001b[1;32md:\\CIT\\Skripsi\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/results/ldavis_prepared_3'"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('/results/ldavis_prepared_'+str(num_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, '/results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
